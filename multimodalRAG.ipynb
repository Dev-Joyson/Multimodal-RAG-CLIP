{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34c8af45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (4.57.3)\n",
      "Requirement already satisfied: langchain in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (1.13.2)\n",
      "Requirement already satisfied: pymupdf in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (1.26.7)\n",
      "Requirement already satisfied: pillow in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (12.1.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from torch) (3.20.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from torch) (2025.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain) (1.2.5)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain) (1.0.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain) (2.12.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.5.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (9.1.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.1)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from requests->transformers) (2.6.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch transformers langchain faiss-cpu pymupdf pillow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8caeb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (1.1.6)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.2 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-openai) (1.2.5)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-openai) (2.14.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.2->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.2->langchain-openai) (0.5.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.2->langchain-openai) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.2->langchain-openai) (2.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.2->langchain-openai) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.2->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.2->langchain-openai) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.2->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.2->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.2->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.2->langchain-openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.2->langchain-openai) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (2.6.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4383239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-text-splitters in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-text-splitters) (1.2.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.5.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.6.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "816819a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-community) (1.2.5)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-community) (2.0.45)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-community) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-community) (3.13.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-community) (0.5.2)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-community) (2.2.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.12.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (25.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.6.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\user\\desktop\\2024\\multimodal-rag-clip\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e50fa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\2024\\Multimodal-RAG-CLIP\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "from langchain_core.documents import Document\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "import base64\n",
    "import io\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e398fe22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CLIPModel(\n",
       "  (text_model): CLIPTextTransformer(\n",
       "    (embeddings): CLIPTextEmbeddings(\n",
       "      (token_embedding): Embedding(49408, 512)\n",
       "      (position_embedding): Embedding(77, 512)\n",
       "    )\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (vision_model): CLIPVisionTransformer(\n",
       "    (embeddings): CLIPVisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "      (position_embedding): Embedding(50, 768)\n",
       "    )\n",
       "    (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (visual_projection): Linear(in_features=768, out_features=512, bias=False)\n",
       "  (text_projection): Linear(in_features=512, out_features=512, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clip Model\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#  set up the environment\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "#  initialize the CLIP model for unified embeddings\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b59ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding functions\n",
    "def embed_image(image_data):\n",
    "    \"\"\"Embed an image using CLIP\"\"\"\n",
    "    if isinstance(image_data, str):\n",
    "        image = Image.open(image_data).convert(\"RGB\")\n",
    "    else:\n",
    "        image = image_data\n",
    "\n",
    "    inputs = clip_processor(images=image, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        features = clip_model.get_image_features(**inputs)\n",
    "        # Normalize embeddings to unit vector\n",
    "        features = features / features.norm(dim=-1, keepdim=True)\n",
    "        return features.squeeze().numpy()\n",
    "\n",
    "def embed_text(text):\n",
    "    \"\"\"Embed text using CLIP\"\"\"\n",
    "    inputs = clip_processor(\n",
    "        text=text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"True\",\n",
    "        truncation=True,\n",
    "        max_length=77 # CLIP max token length\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        features = clip_model.get_text_features(**inputs)\n",
    "        # Normalize embeddings\n",
    "        features = features / features.norm(dim=-1, keepdim=True)\n",
    "        return features.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82d61faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process PDF\n",
    "pdf_path=\"multimodal_sample.pdf\"\n",
    "doc=fitz.open(pdf_path)\n",
    "# Storage for all documents and embeddings\n",
    "all_docs = []\n",
    "all_embeddings = []\n",
    "image_data_store = {} # Store image data for LLM\n",
    "\n",
    "# Text splitter\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8519088",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdoc\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doc' is not defined"
     ]
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb4b456",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "True is not a valid PaddingStrategy, please select one of ['longest', 'max_length', 'do_not_pad']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;31mValueError\u001b[0m: 'True' is not a valid PaddingStrategy",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Embed each chunk using CLIP\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m text_chunks:\n\u001b[1;32m---> 11\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[43membed_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     all_embeddings\u001b[38;5;241m.\u001b[39mappend(embedding)\n\u001b[0;32m     13\u001b[0m     all_docs\u001b[38;5;241m.\u001b[39mappend(chunk)\n",
      "Cell \u001b[1;32mIn[10], line 18\u001b[0m, in \u001b[0;36membed_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21membed_text\u001b[39m(text):\n\u001b[0;32m     17\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Embed text using CLIP\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mclip_processor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m77\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# CLIP max token length\u001b[39;49;00m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     26\u001b[0m         features \u001b[38;5;241m=\u001b[39m clip_model\u001b[38;5;241m.\u001b[39mget_text_features(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\2024\\Multimodal-RAG-CLIP\\.venv\\lib\\site-packages\\transformers\\processing_utils.py:594\u001b[0m, in \u001b[0;36mProcessorMixin.__call__\u001b[1;34m(self, images, text, videos, audio, **kwargs)\u001b[0m\n\u001b[0;32m    592\u001b[0m     input_data, input_kwargs \u001b[38;5;241m=\u001b[39m attribute_to_kwargs[attribute_name]\n\u001b[0;32m    593\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m attribute \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 594\u001b[0m         attribute_output \u001b[38;5;241m=\u001b[39m attribute(input_data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[input_kwargs])\n\u001b[0;32m    595\u001b[0m         outputs\u001b[38;5;241m.\u001b[39mupdate(attribute_output)\n\u001b[0;32m    597\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BatchFeature(outputs)\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\2024\\Multimodal-RAG-CLIP\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3073\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   3071\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   3072\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 3073\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_one(text\u001b[38;5;241m=\u001b[39mtext, text_pair\u001b[38;5;241m=\u001b[39mtext_pair, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mall_kwargs)\n\u001b[0;32m   3074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3075\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\2024\\Multimodal-RAG-CLIP\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3183\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m   3161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[0;32m   3162\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[0;32m   3163\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3180\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3181\u001b[0m     )\n\u001b[0;32m   3182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[0;32m   3184\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m   3185\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   3186\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   3187\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   3188\u001b[0m         truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   3189\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   3190\u001b[0m         stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m   3191\u001b[0m         is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m   3192\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   3193\u001b[0m         padding_side\u001b[38;5;241m=\u001b[39mpadding_side,\n\u001b[0;32m   3194\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m   3195\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   3196\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   3197\u001b[0m         return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   3198\u001b[0m         return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   3199\u001b[0m         return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   3200\u001b[0m         return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m   3201\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   3202\u001b[0m         split_special_tokens\u001b[38;5;241m=\u001b[39msplit_special_tokens,\n\u001b[0;32m   3203\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3204\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\2024\\Multimodal-RAG-CLIP\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3249\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   3206\u001b[0m \u001b[38;5;129m@add_end_docstrings\u001b[39m(ENCODE_KWARGS_DOCSTRING, ENCODE_PLUS_ADDITIONAL_KWARGS_DOCSTRING)\n\u001b[0;32m   3207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mencode_plus\u001b[39m(\n\u001b[0;32m   3208\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3227\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3228\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchEncoding:\n\u001b[0;32m   3229\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3230\u001b[0m \u001b[38;5;124;03m    Tokenize and prepare for the model a sequence or a pair of sequences.\u001b[39;00m\n\u001b[0;32m   3231\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3246\u001b[0m \u001b[38;5;124;03m            method).\u001b[39;00m\n\u001b[0;32m   3247\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3249\u001b[0m     padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   3250\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   3251\u001b[0m         truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   3252\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   3253\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   3254\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   3255\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3256\u001b[0m     )\n\u001b[0;32m   3258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_plus(\n\u001b[0;32m   3259\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m   3260\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3278\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3279\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\2024\\Multimodal-RAG-CLIP\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2920\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._get_padding_truncation_strategies\u001b[1;34m(self, padding, truncation, max_length, pad_to_multiple_of, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2918\u001b[0m     padding_strategy \u001b[38;5;241m=\u001b[39m PaddingStrategy\u001b[38;5;241m.\u001b[39mLONGEST  \u001b[38;5;66;03m# Default to pad to the longest sequence in the batch\u001b[39;00m\n\u001b[0;32m   2919\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(padding, PaddingStrategy):\n\u001b[1;32m-> 2920\u001b[0m     padding_strategy \u001b[38;5;241m=\u001b[39m \u001b[43mPaddingStrategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2921\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(padding, PaddingStrategy):\n\u001b[0;32m   2922\u001b[0m     padding_strategy \u001b[38;5;241m=\u001b[39m padding\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\enum.py:384\u001b[0m, in \u001b[0;36mEnumMeta.__call__\u001b[1;34m(cls, value, names, module, qualname, type, start)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;124;03mEither returns an existing member, or creates a new enum class.\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m`type`, if set, will be mixed in as the first base class.\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# simple value lookup\u001b[39;00m\n\u001b[1;32m--> 384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__new__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;66;03m# otherwise, functional API: we're creating a new Enum type\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_create_(\n\u001b[0;32m    387\u001b[0m         value,\n\u001b[0;32m    388\u001b[0m         names,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m         start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[0;32m    393\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\enum.py:708\u001b[0m, in \u001b[0;36mEnum.__new__\u001b[1;34m(cls, value)\u001b[0m\n\u001b[0;32m    703\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    704\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m._missing_: returned \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m instead of None or a valid member\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    705\u001b[0m             \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, result)\n\u001b[0;32m    706\u001b[0m             )\n\u001b[0;32m    707\u001b[0m exc\u001b[38;5;241m.\u001b[39m__context__ \u001b[38;5;241m=\u001b[39m ve_exc\n\u001b[1;32m--> 708\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\enum.py:692\u001b[0m, in \u001b[0;36mEnum.__new__\u001b[1;34m(cls, value)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    691\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 692\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_missing_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    694\u001b[0m     exc \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\2024\\Multimodal-RAG-CLIP\\.venv\\lib\\site-packages\\transformers\\utils\\generic.py:480\u001b[0m, in \u001b[0;36mExplicitEnum._missing_\u001b[1;34m(cls, value)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_missing_\u001b[39m(\u001b[38;5;28mcls\u001b[39m, value):\n\u001b[1;32m--> 480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, please select one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_value2member_map_\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: True is not a valid PaddingStrategy, please select one of ['longest', 'max_length', 'do_not_pad']"
     ]
    }
   ],
   "source": [
    "for i,page in enumerate(doc):\n",
    "    # Process text\n",
    "    text = page.get_text()\n",
    "    if text.strip():\n",
    "        # create temporary document for splitting\n",
    "        temp_doc = Document(page_content=text, metadata={\"page\": i, \"type\": \"text\"})\n",
    "        text_chunks = splitter.split_documents([temp_doc])\n",
    "\n",
    "        # Embed each chunk using CLIP\n",
    "        for chunk in text_chunks:\n",
    "            embedding = embed_text(chunk.page_content)\n",
    "            all_embeddings.append(embedding)\n",
    "            all_docs.append(chunk)\n",
    "\n",
    "       # Process images\n",
    "        for img_index, img in enumerate(page.get_images(full=True)):\n",
    "            try:\n",
    "                xref = img[0]\n",
    "                base_image = doc.extract_image(xref)\n",
    "                image_bytes = base_image[\"image\"]\n",
    "\n",
    "                # Convert to PIL Image\n",
    "                pil_image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
    "\n",
    "                # Create unique identifier\n",
    "                image_id = f\"page_{i}_img_{img_index}\"\n",
    "\n",
    "                # Store image as base64 for later use with GPT-4V\n",
    "                buffered = io.BytesIO()\n",
    "                pil_image.save(buffered, format=\"PNG\")\n",
    "                image_base64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "                image_data_store[image_id] = image_base64\n",
    "\n",
    "                # Embed image using CLIP\n",
    "                embedding = embed_image(pil_image)\n",
    "                all_embeddings.append(embedding)\n",
    "\n",
    "                # Create document for image\n",
    "                image_doc = Document(\n",
    "                    page_content=f\"[Image: {image_id}]\",\n",
    "                    metadata = {\"page\": i, \"type\": \"image\", \"image_id\": image_id}\n",
    "                )\n",
    "                all_docs.append(image_doc)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {img_index} on page {i}: {e}\")\n",
    "                continue\n",
    "\n",
    "    doc.close()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
